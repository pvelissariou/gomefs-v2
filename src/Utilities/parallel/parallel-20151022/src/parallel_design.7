.\" Automatically generated by Pod::Man 2.27 (Pod::Simple 3.28)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is turned on, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{
.    if \nF \{
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "PARALLEL_DESIGN 7"
.TH PARALLEL_DESIGN 7 "2015-10-18" "20150922" "parallel"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "Design of GNU Parallel"
.IX Header "Design of GNU Parallel"
This document describes design decisions made in the development of
\&\s-1GNU \s0\fBparallel\fR and the reasoning behind them. It will give an
overview of why some of the code looks like it does, and help new
maintainers understand the code better.
.SS "One file program"
.IX Subsection "One file program"
\&\s-1GNU \s0\fBparallel\fR is a Perl script in a single file. It is object
oriented, but contrary to normal Perl scripts each class is not in its
own file. This is due to user experience: The goal is that in a pinch
the user will be able to get \s-1GNU \s0\fBparallel\fR working simply by copying
a single file: No need messing around with environment variables like
\&\s-1PERL5LIB.\s0
.SS "Old Perl style"
.IX Subsection "Old Perl style"
\&\s-1GNU \s0\fBparallel\fR uses some old, deprecated constructs. This is due to a
goal of being able to run on old installations. Currently the target
is CentOS 3.9 and Perl 5.8.0.
.SS "Exponentially back off"
.IX Subsection "Exponentially back off"
\&\s-1GNU \s0\fBparallel\fR busy waits. This is because the reason why a job is
not started may be due to load average, and thus it will not make
sense to wait for a job to finish. Instead the load average must be
checked again. Load average is not the only reason: \-\-timeout has a
similar problem.
.PP
To not burn up too up too much \s-1CPU GNU \s0\fBparallel\fR sleeps
exponentially longer and longer if nothing happens, maxing out at 1
second.
.SS "Shell compatibility"
.IX Subsection "Shell compatibility"
It is a goal to have \s-1GNU \s0\fBparallel\fR work equally well in any
shell. However, in practice \s-1GNU \s0\fBparallel\fR is being developed in
\&\fBbash\fR and thus testing in other shells is limited to reported bugs.
.PP
When an incompatibility is found there is often not an easy fix:
Fixing the problem in \fBcsh\fR often breaks it in \fBbash\fR. In these
cases the fix is often to use a small Perl script and call that.
.SS "Job slots"
.IX Subsection "Job slots"
The easiest way to explain what \s-1GNU \s0\fBparallel\fR does is to assume that
there are a number of job slots, and when a slot becomes available a
job from the queue will be run in that slot. But originally \s-1GNU
\&\s0\fBparallel\fR did not model job slots in the code. Job slots have been
added to make it possible to use {%} as a replacement string.
.PP
Job slots were added to the code in 20140522, but while the job
sequence number can be computed in advance, the job slot can only be
computed the moment a slot becomes available. So it has been
implemented as a stack with lazy evaluation: Draw one from an empty
stack and the stack is extended by one. When a job is done, push the
available job slot back on the stack.
.PP
This implementation also means that if you use remote executions, you
cannot assume that a given job slot will remain on the same remote
server. This goes double since number of job slots can be adjusted on
the fly (by giving \fB\-\-jobs\fR a file name).
.SS "Rsync protocol version"
.IX Subsection "Rsync protocol version"
\&\fBrsync\fR 3.1.x uses protocol 31 which is unsupported by version
2.5.7. That means that you cannot push a file to a remote system using
\&\fBrsync\fR protocol 31, if the remote system uses 2.5.7. \fBrsync\fR does
not automatically downgrade to protocol 30.
.PP
\&\s-1GNU \s0\fBparallel\fR does not require protocol 31, so if the \fBrsync\fR
version is >= 3.1.0 then \fB\-\-protocol 30\fR is added to force newer
\&\fBrsync\fRs to talk to version 2.5.7.
.SS "Compression"
.IX Subsection "Compression"
\&\fB\-\-compress\fR compresses the data in the temporary files. This is a
bit tricky because there should be no files to clean up if \s-1GNU
\&\s0\fBparallel\fR is killed by a power outage.
.PP
\&\s-1GNU \s0\fBparallel\fR first selects a compress program. If the user has not
selected one, the first of these that are in \f(CW$PATH\fR is used: \fBlz4 pigz
lzop plzip pbzip2 pxz gzip lzma xz bzip2 lzip\fR. They are sorted by
speed on a 16 core machine.
.PP
Schematically the setup is as follows:
.PP
.Vb 2
\&  command started by parallel | compress > tmpfile
\&  cattail tmpfile | uncompress | parallel
.Ve
.PP
The setup is duplicated for both standard output (stdout) and standard
error (stderr).
.PP
\&\s-1GNU \s0\fBparallel\fR pipes output from the command run into the compress
program which saves to a tmpfile. \s-1GNU \s0\fBparallel\fR records the pid of
the compress program.  At the same time a small perl script (called
\&\fBcattail\fR above) is started: It basically does \fBcat\fR followed by
\&\fBtail \-f\fR, but it also removes the tmpfile as soon as the first byte
is read, and it continously checks if the pid of the compress program
is dead. If the compress program is dead, \fBcattail\fR reads the rest of
tmpfile and exits.
.PP
As most compress programs write out a header when they start, the
tmpfile in practice is unlinked after around 40 ms.
.SS "Wrapping"
.IX Subsection "Wrapping"
The command given by the user can be wrapped in multiple
templates. Templates can be wrapped in other templates.
.IP "\-\-shellquote" 15
.IX Item "--shellquote"
echo \fIshell double quoted input\fR
.IP "\-\-nice \fIpri\fR" 15
.IX Item "--nice pri"
Remote: See \fBThe remote system wrapper\fR.
.Sp
Local: \fBsetpriority(0,0,$nice)\fR
.IP "\-\-cat" 15
.IX Item "--cat"
cat > {}; \fIinput\fR {};
perl \-e '$bash = shift;
         \f(CW$csh\fR = shift;
         for(@ARGV) {
           unlink;rmdir;
         }
         if($bash =~ s/h//) {
           exit \f(CW$bash\fR;
         }
         exit \f(CW$csh\fR;' \*(L"$?h\*(R" \*(L"$status\*(R" {};
.Sp
{} is set to \f(CW$PARALLEL_TMP\fR which is a tmpfile. The Perl script saves
the exit value, unlinks the tmpfile, and returns the exit value \- no
matter if the shell is \fBbash\fR (using $?) or \fB*csh\fR (using \f(CW$status\fR).
.IP "\-\-fifo" 15
.IX Item "--fifo"
perl \-e '($s,$c,$f) = \f(CW@ARGV\fR;
         # mkfifo \f(CW$PARALLEL_TMP\fR
         system \*(L"mkfifo\*(R", \f(CW$f\fR;
         # spawn \f(CW$shell\fR \-c \f(CW$command\fR &
         \f(CW$pid\fR = fork || exec \f(CW$s\fR, \*(L"\-c\*(R", \f(CW$c\fR;
         open($o,\*(L">\*(R",$f) || die $!;
         # cat > \f(CW$PARALLEL_TMP\fR
         while(sysread(\s-1STDIN\s0,$buf,131072)){
            syswrite \f(CW$o\fR, \f(CW$buf\fR;
         }
         close \f(CW$o\fR;
         # waitpid to get the exit code from \f(CW$command\fR
         waitpid \f(CW$pid\fR,0;
         # Cleanup
         unlink \f(CW$f\fR;
         exit $?/256;' \fIshell\fR \fIinput\fR \f(CW$PARALLEL_TMP\fR
.Sp
This is an elaborate way of: mkfifo {}; run \fIinput\fR in the
background using \fIshell\fR; copying \s-1STDIN\s0 to {}; waiting for background
to complete; remove {} and exit with the exit code from \fIinput\fR.
.Sp
It is made this way to be compatible with \fB*csh\fR.
.IP "\-\-sshlogin \fIsln\fR" 15
.IX Item "--sshlogin sln"
ssh \fIsln\fR \fIshell quoted input\fR
.IP "\-\-transfer" 15
.IX Item "--transfer"
( ssh \fIsln\fR mkdir \-p ./\fIworkdir\fR;rsync \-\-protocol 30 \-rlDzR \-essh ./{} \fIsln\fR:./\fIworkdir\fR ); \fIinput\fR
.Sp
Read about \fB\-\-protocol 30\fR in the section \fBRsync protocol version\fR.
.IP "\-\-basefile" 15
.IX Item "--basefile"
<<todo>>
.IP "\-\-return \fIfile\fR" 15
.IX Item "--return file"
\&\fIinput\fR; _EXIT_status=$?; mkdir \-p \fIworkdir\fR; rsync \-\-protocol 30 \-\-rsync\-path=cd\e ./\fIworkdir\fR\e;\e rsync \-rlDzR \-essh \fIsln\fR:./\fIfile\fR ./\fIworkdir\fR; exit \f(CW$_EXIT_status\fR;
.Sp
The \fB\-\-rsync\-path=cd ...\fR is needed because old versions of \fBrsync\fR
do not support \fB\-\-no\-implied\-dirs\fR.
.Sp
The \fB\f(CB$_EXIT_status\fB\fR trick is to postpone the exit value. This makes it
incompatible with \fB*csh\fR and should be fixed in the future. Maybe a
wrapping 'sh \-c' is enough?
.IP "\-\-cleanup" 15
.IX Item "--cleanup"
\&\fIinput\fR _EXIT_status=$?; <<return>>
.Sp
ssh \fIsln\fR \e(rm\e \-f\e ./\fIworkdir\fR/{}\e;\e rmdir\e ./\fIworkdir\fR\e \e>\e&/dev/null\e;\e); exit \f(CW$_EXIT_status\fR;
.Sp
\&\fB\f(CB$_EXIT_status\fB\fR: see \fB\-\-return\fR above.
.IP "\-\-pipe" 15
.IX Item "--pipe"
perl \-e 'if(sysread(\s-1STDIN,\s0 \f(CW$buf\fR, 1)) {
		open($fh, \*(L"|\-\*(R", \*(L"@ARGV\*(R") || die;
		syswrite($fh, \f(CW$buf\fR);
		# Align up to 128k block
		if($read = sysread(\s-1STDIN,\s0 \f(CW$buf\fR, 131071)) {
		    syswrite($fh, \f(CW$buf\fR);
		}
		while($read = sysread(\s-1STDIN,\s0 \f(CW$buf\fR, 131072)) {
		    syswrite($fh, \f(CW$buf\fR);
		}
		close \f(CW$fh\fR;
		exit ($?&127 ? 128+($?&127) : 1+$?>>8)
	    }' \fIshell\fR \-c \fIinput\fR
.Sp
This small wrapper makes sure that \fIinput\fR will never be run if
there is no data.
.IP "\-\-tmux" 15
.IX Item "--tmux"
<<\s-1TODO\s0 Fixup>>
mkfifo /tmp/tmx3cMEV &&
  sh \-c 'tmux \-S /tmp/tmsaKpv1 new-session \-s p334310 \-d \*(L"sleep .2\*(R" >/dev/null 2>&1';
tmux \-S /tmp/tmsaKpv1 new-window \-t p334310 \-n wc\e 10 \e(wc\e 10\e)\e;\e perl\e \-e\e \e'while\e(\e$t++\e<3\e)\e{\e print\e \e$ARGV\e[0\e],\e\*(L"\e\en\e\*(R"\e \e}\e'\e \e$\e?h/\e$status\e \e>\e>\e /tmp/tmx3cMEV\e&echo\e wc\e\e\e 10\e;\e echo\e \eJob\e finished\e at:\e \e`date\e`\e;sleep\e 10;
exec perl \-e '$/=\*(L"/\*(R";$_=<>;$c=<>;unlink \f(CW$ARGV\fR; /(\ed+)h/ and exit($1);exit$c' /tmp/tmx3cMEV
.Sp
mkfifo \fItmpfile.tmx\fR;
tmux \-S <tmpfile.tms> new-session \-s p\fI\s-1PID\s0\fR \-d 'sleep .2' >&/dev/null;
tmux \-S <tmpfile.tms> new-window \-t p\fI\s-1PID\s0\fR \-n <<shell quoted input>> \e(<<shell quoted input>>\e)\e;\e perl\e \-e\e \e'while\e(\e$t++\e<3\e)\e{\e print\e \e$ARGV\e[0\e],\e\*(L"\e\en\e\*(R"\e \e}\e'\e \e$\e?h/\e$status\e \e>\e>\e \fItmpfile.tmx\fR\e&echo\e <<shell double quoted input>>\e;echo\e \eJob\e finished\e at:\e \e`date\e`\e;sleep\e 10;
exec perl \-e '$/=\*(L"/\*(R";$_=<>;$c=<>;unlink \f(CW$ARGV\fR; /(\ed+)h/ and exit($1);exit$c' \fItmpfile.tmx\fR
.Sp
First a \s-1FIFO\s0 is made (.tmx). It is used for communicating exit
value. Next a new tmux session is made. This may fail if there is
already a session, so the output is ignored. If all job slots finish
at the same time, then \fBtmux\fR will close the session. A temporary
socket is made (.tms) to avoid a race condition in \fBtmux\fR. It is
cleaned up when \s-1GNU \s0\fBparallel\fR finishes.
.Sp
The input is used as the name of the windows in \fBtmux\fR. When the job
inside \fBtmux\fR finishes, the exit value is printed to the \s-1FIFO \s0(.tmx).
This \s-1FIFO\s0 is opened by \fBperl\fR outside \fBtmux\fR, and \fBperl\fR then
removes the \s-1FIFO. \s0\fBPerl\fR blocks until the first value is read from
the \s-1FIFO,\s0 and this value is used as exit value.
.Sp
To make it compatible with \fBcsh\fR and \fBbash\fR the exit value is
printed as: $?h/$status and this is parsed by \fBperl\fR.
.Sp
Works in \fBcsh\fR.
.Sp
There is a bug that makes it necessary to print the exit value 3
times.
.Sp
Another bug in \fBtmux\fR requires the length of the tmux title and
command to not have certain limits.  When inside these limits, 75 '\e '
are added to the title to force it to be outside the limits.
.Sp
You can map the bad limits using:
.Sp
perl \-e 'sub r { int(rand(shift)).($_[0] && \*(L"\et\*(R".r(@_)) } print map { r(@ARGV).\*(L"\en\*(R" } 1..10000' 1600 1500 90 |
  perl \-ane '$F[0]+$F[1]+$F[2] < 2037 and print ' | 
  parallel \-\-colsep '\et' \-\-tagstring '{1}\et{2}\et{3}' tmux \-S /tmp/p{%}\-'{=3 \f(CW$_\fR=\*(L"O\*(R"x$_ =}' \e
    new-session \-d \-n '{=1 \f(CW$_\fR=\*(L"O\*(R"x$_ =}' true'\e {=2 \f(CW$_\fR=\*(L"O\*(R"x$_ =};echo $?;rm \-f /tmp/p{%}\-O*'
.Sp
perl \-e 'sub r { int(rand(shift)).($_[0] && \*(L"\et\*(R".r(@_)) } print map { r(@ARGV).\*(L"\en\*(R" } 1..10000' 17000 17000 90 |
  parallel \-\-colsep '\et' \-\-tagstring '{1}\et{2}\et{3}' \e
tmux \-S /tmp/p{%}\-'{=3 \f(CW$_\fR=\*(L"O\*(R"x$_ =}' new-session \-d \-n '{=1 \f(CW$_\fR=\*(L"O\*(R"x$_ =}' true'\e {=2 \f(CW$_\fR=\*(L"O\*(R"x$_ =};echo $?;rm /tmp/p{%}\-O*'
> value.csv 2>/dev/null
.Sp
R \-e 'a<\-read.table(\*(L"value.csv\*(R");\fIX11()\fR;plot(a[,1],a[,2],col=a[,3]+5,cex=0.1);Sys.sleep(1000)'
.Sp
For \fBtmux 1.8\fR 17000 can be lowered to 2100.
.Sp
The interesting areas are title 0..1000 with (title + whole command)
in 996..1127 and 9331..9636.
.PP
The ordering of the wrapping is important:
.IP "\(bu" 5
\&\fB\-\-nice\fR/\fB\-\-cat\fR/\fB\-\-fifo\fR should be done on the remote machine
.IP "\(bu" 5
\&\fB\-\-pipepart\fR/\fB\-\-pipe\fR should be done on the local machine inside \fB\-\-tmux\fR
.SS "\-\-block\-size adjustment"
.IX Subsection "--block-size adjustment"
Every time \s-1GNU \s0\fBparallel\fR detects a record bigger than
\&\fB\-\-block\-size\fR it increases the block size by 30%. A small
\&\fB\-\-block\-size\fR gives very poor performance; by exponentially
increasing the block size performance will not suffer.
.PP
\&\s-1GNU \s0\fBparallel\fR will waste \s-1CPU\s0 power if \fB\-\-block\-size\fR does not
contain a full record, because it tries to find a full record and will
fail to do so. The recommendation is therefore to use a
\&\fB\-\-block\-size\fR > 2 records, so you always get at least one full
record when you read one block.
.PP
If you use \fB\-N\fR then \fB\-\-block\-size\fR should be big enough to contain
N+1 records.
.SS "Convenience options \-\-nice \-\-basefile \-\-transfer \-\-return \-\-cleanup \-\-tmux \-\-group \-\-compress \-\-cat \-\-fifo \-\-workdir"
.IX Subsection "Convenience options --nice --basefile --transfer --return --cleanup --tmux --group --compress --cat --fifo --workdir"
These are all convenience options that make it easier to do a
task. But more importantly: They are tested to work on corner cases,
too. Take \fB\-\-nice\fR as an example:
.PP
.Vb 1
\&  nice parallel command ...
.Ve
.PP
will work just fine. But when run remotely, you need to move the nice
command so it is being run on the server:
.PP
.Vb 1
\&  parallel \-S server nice command ...
.Ve
.PP
And this will again work just fine, as long as you are running a
single command. When you are running a composed command you need nice
to apply to the whole command, and it gets harder still:
.PP
.Vb 1
\&  parallel \-S server \-q nice bash \-c \*(Aqcommand1 ...; command2 | command3\*(Aq
.Ve
.PP
It is not impossible, but by using \fB\-\-nice\fR \s-1GNU \s0\fBparallel\fR will do
the right thing for you. Similarly when transferring files: It starts
to get hard when the file names contain space, :, `, *, or other
special characters.
.PP
To run the commands in a \fBtmux\fR session you basically just need to
quote the command. For simple commands that is easy, but when commands
contain special characters, it gets much harder to get right.
.PP
\&\fB\-\-cat\fR and \fB\-\-fifo\fR are easy to do by hand, until you want to clean
up the tmpfile and keep the exit code of the command.
.PP
The real killer comes when you try to combine several of these: Doing
that correctly for all corner cases is next to impossible to do by
hand.
.SS "Shell shock"
.IX Subsection "Shell shock"
The shell shock bug in \fBbash\fR did not affect \s-1GNU \s0\fBparallel\fR, but the
solutions did. \fBbash\fR first introduced functions in variables named:
\&\fI\fIBASH_FUNC_myfunc()\fI\fR and later changed that to \fIBASH_FUNC_myfunc%%\fR. When
transferring functions \s-1GNU \s0\fBparallel\fR reads off the function and changes
that into a function definition, which is copied to the remote system and
executed before the actual command is executed. Therefore \s-1GNU \s0\fBparallel\fR
needs to know how to read the function.
.PP
From version 20150122 \s-1GNU \s0\fBparallel\fR tries both the ()\-version and
the %%\-version, and the function definition works on both pre\- and
post-shellshock versions of \fBbash\fR.
.SS "The remote system wrapper"
.IX Subsection "The remote system wrapper"
The remote system wrapper does some initialization before starting the
command on the remote system.
.PP
\fICtrl-C and standard error (stderr)\fR
.IX Subsection "Ctrl-C and standard error (stderr)"
.PP
If the user presses Ctrl-C the user expects jobs to stop. This works
out of the box if the jobs are run locally. Unfortunately it is not so
simple if the jobs are run remotely.
.PP
If remote jobs are run in a tty using \fBssh \-tt\fR, then Ctrl-C works,
but all output to standard error (stderr) is sent to standard output
(stdout). This is not what the user expects.
.PP
If remote jobs are run without a tty using \fBssh\fR (without \fB\-tt\fR),
then output to standard error (stderr) is kept on stderr, but Ctrl-C
does not kill remote jobs. This is not what the user expects.
.PP
So what is needed is a way to have both. It seems the reason why
Ctrl-C does not kill the remote jobs is because the shell does not
propagate the hang-up signal from \fBsshd\fR. But when \fBsshd\fR dies, the
parent of the login shell becomes \fBinit\fR (process id 1). So by
exec'ing a Perl wrapper to monitor the parent pid and kill the child
if the parent pid becomes 1, then Ctrl-C works and stderr is kept on
stderr.
.PP
\fI\-\-nice\fR
.IX Subsection "--nice"
.PP
\&\fBnice\fRing the remote process is done by \fBsetpriority(0,0,$nice)\fR. A
few old systems do not implement this and is thus unsupported.
.PP
\fISetting \f(CI$PARALLEL_TMP\fI\fR
.IX Subsection "Setting $PARALLEL_TMP"
.PP
\&\fB\f(CB$PARALLEL_TMP\fB\fR is used by \fB\-\-fifo\fR and \fB\-\-cat\fR and must point to a
non-exitent file in \fB\f(CB$TMPDIR\fB\fR. This file name is computed on the
remote system.
.PP
\fIThe wrapper\fR
.IX Subsection "The wrapper"
.PP
The wrapper looks like this:
.PP
.Vb 10
\&    $shell = $PARALLEL_SHELL || $SHELL;
\&    $tmpdir = $TMPDIR;
\&    $nice = $opt::nice;
\&    # Set $PARALLEL_TMP to a non\-existent file name in $TMPDIR
\&    do {
\&        $ENV{PARALLEL_TMP} = $tmpdir."/par".
\&            join"", map { (0..9,"a".."z","A".."Z")[rand(62)] } (1..5);
\&    } while(\-e $ENV{PARALLEL_TMP});
\&    $SIG{CHLD} = sub { $done = 1; };
\&    $pid = fork;
\&    unless($pid) {
\&        # Make own process group to be able to kill HUP it later
\&        setpgrp;
\&        eval { setpriority(0,0,$nice) };
\&        exec $shell, "\-c", ($bashfunc."@ARGV");
\&        die "exec: $!\en";
\&    }
\&    do {
\&        # Parent is not init (ppid=1), so sshd is alive
\&        # Exponential sleep up to 1 sec
\&        $s = $s < 1 ? 0.001 + $s * 1.03 : $s;
\&        select(undef, undef, undef, $s);
\&    } until ($done || getppid == 1);
\&    # Kill HUP the process group if job not done
\&    kill(SIGHUP, \-${pid}) unless $done;
\&    wait;
\&    exit ($?&127 ? 128+($?&127) : 1+$?>>8)
.Ve
.SS "Transferring of variables and functions"
.IX Subsection "Transferring of variables and functions"
Transferring of variables and functions given by \fB\-\-env\fR is done by
running a Perl script remotely that calls the actual command. The Perl
script sets \f(CW$ENV\fR{variable} to the correct value before exec'ing the a
shell that runs the function definition followed by the actual
command.
.PP
\&\fBenv_parallel\fR (mentioned in the man page) copies the full current
environment into the environment variable \fB\s-1PARALLEL_ENV\s0\fR. This
variable is picked up by \s-1GNU \s0\fBparallel\fR and used to create the Perl
script mentioned above.
.SS "Base64 encoded bzip2"
.IX Subsection "Base64 encoded bzip2"
\&\fBcsh\fR limits words of commands to 1024 chars. This is often too little
when \s-1GNU \s0\fBparallel\fR encodes environment variables and wraps the
command with different templates. All of these are combined and quoted
into one single word, which often is longer than 1024 chars.
.PP
When the line to run is > 1000 chars, \s-1GNU \s0\fBparallel\fR therefore
encodes the line to run. The encoding \fBbzip2\fRs the line to run,
converts this to base64, splits the base64 into 1000 char blocks (so \fBcsh\fR
does not fail), and prepends it with this Perl script that decodes,
decompresses and \fBeval\fRs the line.
.PP
.Vb 2
\&    @GNU_Parallel=("use","IPC::Open3;","use","MIME::Base64");
\&    eval "@GNU_Parallel";
\&
\&    $SIG{CHLD}="IGNORE";
\&    # Search for bzip2. Not found => use default path
\&    my $zip = (grep { \-x $_ } "/usr/local/bin/bzip2")[0] || "bzip2";
\&    # $in = stdin on $zip, $out = stdout from $zip
\&    my($in, $out,$eval);
\&    open3($in,$out,">&STDERR",$zip,"\-dc");
\&    if(my $perlpid = fork) {
\&        close $in;
\&        $eval = join "", <$out>;
\&        close $out;
\&    } else {
\&        close $out;
\&        # Pipe decoded base64 into \*(Aqbzip2 \-dc\*(Aq
\&        print $in (decode_base64(join"",@ARGV));
\&        close $in;
\&        exit;
\&    }
\&    wait;
\&    eval $eval;
.Ve
.PP
Perl and \fBbzip2\fR must be installed on the remote system, but a small
test showed that \fBbzip2\fR is installed by default on all platforms
that runs \s-1GNU \s0\fBparallel\fR, so this is not a big problem.
.PP
The added bonus of this is that much bigger environments can now be
transferred as they will be below \fBbash\fR's limit of 131072 chars.
.SS "Which shell to use"
.IX Subsection "Which shell to use"
Different shells behave differently. A command that works in \fBtcsh\fR
may not work in \fBbash\fR.  It is therefore important that the correct
shell is used when \s-1GNU \s0\fBparallel\fR executes commands.
.PP
\&\s-1GNU \s0\fBparallel\fR tries hard to use the right shell. If \s-1GNU \s0\fBparallel\fR
is called from \fBtcsh\fR it will use \fBtcsh\fR.  If it is called from
\&\fBbash\fR it will use \fBbash\fR. It does this by looking at the
(grand*)parent process: If the (grand*)parent process is a shell, use
this shell; otherwise look at the parent of this (grand*)parent. If
none of the (grand*)parents are shells, then \f(CW$SHELL\fR is used.
.PP
This will do the right thing if called from:
.IP "\(bu" 2
an interactive shell
.IP "\(bu" 2
a shell script
.IP "\(bu" 2
a Perl script in `` or using \fBsystem\fR if called as a single string.
.PP
While these cover most cases, there are situations where it will fail:
.IP "\(bu" 2
When run using \fBexec\fR.
.IP "\(bu" 2
When run as the last command using \fB\-c\fR from another shell (because
some shells use \fBexec\fR):
.Sp
.Vb 1
\&  zsh% bash \-c "parallel \*(Aqecho {} is not run in bash; set | grep BASH_VERSION\*(Aq ::: This"
.Ve
.Sp
You can work around that by appending '&& true':
.Sp
.Vb 1
\&  zsh% bash \-c "parallel \*(Aqecho {} is run in bash; set | grep BASH_VERSION\*(Aq ::: This && true"
.Ve
.IP "\(bu" 2
When run in a Perl script using \fBsystem\fR with parallel as the first
string:
.Sp
.Vb 1
\&  #!/usr/bin/perl
\&
\&  system("parallel",\*(Aqsetenv a {}; echo $a\*(Aq,":::",2);
.Ve
.Sp
Here it depends on which shell is used to call the Perl script. If the
Perl script is called from \fBtcsh\fR it will work just fine, but if it
is called from \fBbash\fR it will fail, because the command \fBsetenv\fR is
not known to \fBbash\fR.
.PP
If \s-1GNU \s0\fBparallel\fR guesses wrong in these situation, set the shell using
\&\f(CW$PARALLEL_SHELL\fR.
.SS "Quoting"
.IX Subsection "Quoting"
Quoting depends on the shell. For most shells \e is used for all
special chars and ' is used for newline. Whether a char is special
depends on the shell and the context. Luckily quoting a bit too many
chars does not break things.
.PP
It is fast, but had the distinct disadvantage that if a string needs
to be quoted multiple times, the \e's double every time \- increasing
the string length exponentially.
.PP
For \fBtcsh\fR/\fBcsh\fR newline is quoted as \e followed by newline.
.PP
For \fBrc\fR everything is quoted using '.
.SS "\-\-pipepart vs. \-\-pipe"
.IX Subsection "--pipepart vs. --pipe"
While \fB\-\-pipe\fR and \fB\-\-pipepart\fR look much the same to the user, they are
implemented very differently.
.PP
With \fB\-\-pipe\fR \s-1GNU \s0\fBparallel\fR reads the blocks from standard input
(stdin), which is then given to the command on standard input (stdin);
so every block is being processed by \s-1GNU \s0\fBparallel\fR itself. This is
the reason why \fB\-\-pipe\fR maxes out at around 100 MB/sec.
.PP
\&\fB\-\-pipepart\fR, on the other hand, first identifies at which byte
positions blocks start and how long they are. It does that by seeking
into the file by the size of a block and then reading until it meets
end of a block. The seeking explains why \s-1GNU \s0\fBparallel\fR does not know
the line number and why \fB\-L/\-l\fR and \fB\-N\fR do not work.
.PP
With a reasonable block and file size this seeking is often more than
1000 faster than reading the full file. The byte positions are then
given to a small script that reads from position X to Y and sends
output to standard output (stdout). This small script is prepended to
the command and the full command is executed just as if \s-1GNU
\&\s0\fBparallel\fR had been in its normal mode. The script looks like this:
.PP
.Vb 7
\&  < file perl \-e \*(Aqwhile(@ARGV) { 
\&     sysseek(STDIN,shift,0) || die;
\&     $left = shift;
\&     while($read = sysread(STDIN,$buf, ($left > 32768 ? 32768 : $left))){
\&       $left \-= $read; syswrite(STDOUT,$buf);
\&     }
\&  }\*(Aq startbyte length_in_bytes
.Ve
.PP
It delivers 1 GB/s per core.
.PP
Instead of the script \fBdd\fR was tried, but many versions of \fBdd\fR do
not support reading from one byte to another and might cause partial
data. See this for a surprising example:
.PP
.Vb 1
\&  yes | dd bs=1024k count=10 | wc
.Ve
.SS "\-\-jobs and \-\-onall"
.IX Subsection "--jobs and --onall"
When running the same commands on many servers what should \fB\-\-jobs\fR
signify? Is it the number of servers to run on in parallel?  Is it the
number of jobs run in parallel on each server?
.PP
\&\s-1GNU \s0\fBparallel\fR lets \fB\-\-jobs\fR represent the number of servers to run
on in parallel. This is to make it possible to run a sequence of
commands (that cannot be parallelized) on each server, but run the
same sequence on multiple servers.
.SS "Buffering on disk"
.IX Subsection "Buffering on disk"
\&\s-1GNU \s0\fBparallel\fR buffers on disk in \f(CW$TMPDIR\fR using files, that are
removed as soon as they are created, but which are kept open. So even
if \s-1GNU \s0\fBparallel\fR is killed by a power outage, there will be no files
to clean up afterwards. Another advantage is that the file system is
aware that these files will be lost in case of a crash, so it does
not need to sync them to disk.
.PP
It gives the odd situation that a disk can be fully used, but there
are no visible files on it.
.SS "Disk full"
.IX Subsection "Disk full"
\&\s-1GNU \s0\fBparallel\fR buffers on disk. If the disk is full data may be
lost. To check if the disk is full \s-1GNU \s0\fBparallel\fR writes a 8193 byte
file when a job finishes. If this file is written successfully, it is
removed immediately. If it is not written successfully, the disk is
full. The size 8193 was chosen because 8192 gave wrong result on some
file systems, whereas 8193 did the correct thing on all tested
filesystems.
.SS "Perl replacement strings, {= =}, and \-\-rpl"
.IX Subsection "Perl replacement strings, {= =}, and --rpl"
The shorthands for replacement strings make a command look more
cryptic. Different users will need different replacement
strings. Instead of inventing more shorthands you get more more
flexible replacement strings if they can be programmed by the user.
.PP
The language Perl was chosen because \s-1GNU \s0\fBparallel\fR is written in
Perl and it was easy and reasonably fast to run the code given by the
user.
.PP
If a user needs the same programmed replacement string again and
again, the user may want to make his own shorthand for it. This is
what \fB\-\-rpl\fR is for. It works so well, that even \s-1GNU \s0\fBparallel\fR's
own shorthands are implemented using \fB\-\-rpl\fR.
.PP
In Perl code the bigrams {= and =} rarely exist. They look like a
matching pair and can be entered on all keyboards. This made them good
candidates for enclosing the Perl expression in the replacement
strings. Another candidate ,, and ,, was rejected because they do not
look like a matching pair. \fB\-\-parens\fR was made, so that the users can
still use ,, and ,, if they like: \fB\-\-parens ,,,,\fR
.PP
Internally, however, the {= and =} are replaced by \e257< and
\&\e257>. This is to make it simple to make regular expressions: \e257 is
disallowed on the command line, so when that is matched in a regular
expression, it is known that this is a replacement string.
.SS "Test suite"
.IX Subsection "Test suite"
\&\s-1GNU \s0\fBparallel\fR uses its own testing framework. This is mostly due to
historical reasons. It deals reasonably well with tests that are
dependent on how long a given test runs (e.g. more than 10 secs is a
pass, but less is a fail). It parallelizes most tests, but it is easy
to force a test to run as the single test (which may be important for
timing issues). It deals reasonably well with tests that fail
intermittently. It detects which tests failed and pushes these to the
top, so when running the test suite again, the tests that failed most
recently are run first.
.PP
If \s-1GNU \s0\fBparallel\fR should adopt a real testing framework then those
elements would be important.
.PP
Since many tests are dependent on which hardware it is running on,
these tests break when run on a different hardware than what the test
was written for.
.PP
When most bugs are fixed a test is added, so this bug will not
reappear. It is, however, sometimes hard to create the environment in
which the bug shows up \- especially if the bug only shows up
sometimes. One of the harder problems was to make a machine start
swapping without forcing it to its knees.
.SS "Median run time"
.IX Subsection "Median run time"
Using a percentage for \fB\-\-timeout\fR causes \s-1GNU \s0\fBparallel\fR to compute
the median run time of a job. The median is a better indicator of the
expected run time than average, because there will often be outliers
taking way longer than the normal run time.
.PP
To avoid keeping all run times in memory, an implementation of
remedian was made (Rousseeuw et al).
.SS "Error messages and warnings"
.IX Subsection "Error messages and warnings"
Error messages like: \s-1ERROR,\s0 Not found, and 42 are not very
helpful. \s-1GNU \s0\fBparallel\fR strives to inform the user:
.IP "\(bu" 2
What went wrong?
.IP "\(bu" 2
Why did it go wrong?
.IP "\(bu" 2
What can be done about it?
.PP
Unfortunately it is not always possible to predict the root cause of the error.
.SS "Computation of load"
.IX Subsection "Computation of load"
Contrary to the obvious \fB\-\-load\fR does not use load average. This is
due to load average rising too slowly. Instead it uses \fBps\fR to list
the number of jobs in running or blocked state (state D, O or R). This
gives an instant load.
.PP
As remote calculation of load can be slow, a process is spawned to run
\&\fBps\fR and put the result in a file, which is then used next time.
.SS "Killing jobs"
.IX Subsection "Killing jobs"
\&\fB\-\-memfree\fR, \fB\-\-halt\fR and when \s-1GNU \s0\fBparallel\fR meets a condition
from which it cannot recover, jobs are killed. This is done by finding
the (grand)*children of the jobs and killing those processes.
.PP
More specifically \s-1GNU \s0\fBparallel\fR maintains a list of processes to be
killed, sends a signal to all processes (first round this is a \s-1TERM\s0).
It weeds out the processes that exited from the list then waits a
while and weeds out again. It does that until all processes are dead
or 200 ms passed. Then it does another round with \s-1TERM,\s0 and finally a
round with \s-1KILL.\s0
.PP
.Vb 9
\&  pids = family_pids(jobs)
\&  for signal in TERM, TERM, KILL:
\&    for pid in pids:
\&      kill signal, pid
\&    while kill 0, pids and slept < 200 ms:
\&      sleep sleeptime
\&      pids = kill 0, pids
\&      slept += sleeptime
\&      sleeptime = sleeptime * 1.1
.Ve
.PP
By doing so there is a tiny risk, that \s-1GNU \s0\fBparallel\fR will kill
processes that are not started from \s-1GNU \s0\fBparallel\fR. It, however,
requires all of these to be true:
.PP
* Process A is sent a signal
* It dies during a \fIsleep sleeptime\fR cycle
* A new process B is spawned (by an unrelated process)
* This is done during the same \fIsleep sleeptime\fR cycle
* B is owned by the same user
* B reuses the pid of the A
.PP
It is considered unlikely to ever happen due to:
.PP
* The longest \fIsleep sleeptime\fR sleeps is 10 ms
* Re-use of a dead pid rarely happens within a few seconds
.SH "Ideas for new design"
.IX Header "Ideas for new design"
.SS "Multiple processes working together"
.IX Subsection "Multiple processes working together"
Open3 is slow. Printing is slow. It would be good if they did not tie
up ressources, but were run in separate threads.
.SS "Transferring of variables and functions from zsh"
.IX Subsection "Transferring of variables and functions from zsh"
Transferring Bash functions to remote zsh works.
Can parallel_bash_environment be used to import zsh functions?
.SS "\-\-rrs on remote using a perl wrapper"
.IX Subsection "--rrs on remote using a perl wrapper"
\&... | perl \-pe '$/=$recend$recstart;BEGIN{ if(substr($_) eq \f(CW$recstart\fR) substr($_)="\*(L" } eof and substr($_) eq \f(CW$recend\fR) substr($_)=\*(R""
.PP
It ought to be possible to write a filter that removed rec sep on the
fly instead of inside \s-1GNU \s0\fBparallel\fR. This could then use more cpus.
.PP
Will that require 2x record size memory?
.PP
Will that require 2x block size memory?
.SH "Historical decisions"
.IX Header "Historical decisions"
.SS "\-\-tollef"
.IX Subsection "--tollef"
You can read about the history of \s-1GNU \s0\fBparallel\fR on https://www.gnu.org/software/parallel/history.html
.PP
\&\fB\-\-tollef\fR was included to make \s-1GNU \s0\fBparallel\fR switch compatible
with the parallel from moreutils (which is made by Tollef Fog
Heen). This was done so that users of that parallel easily could port
their use to \s-1GNU \s0\fBparallel\fR: Simply set \fBPARALLEL=\*(L"\-\-tollef\*(R"\fR and
that would be it.
.PP
But several distributions chose to make \fB\-\-tollef\fR global (by putting it
into /etc/parallel/config), and that caused much confusion when people
tried out the examples from \s-1GNU \s0\fBparallel\fR's man page and these did
not work.  The users became frustrated because the distribution did
not make it clear to them that it has made \fB\-\-tollef\fR global.
.PP
So to lessen the frustration and the resulting support, \fB\-\-tollef\fR
was obsoleted 20130222 and removed one year later.
.SS "Transferring of variables and functions"
.IX Subsection "Transferring of variables and functions"
Until 20150122 variables and functions were transferred by looking at
\&\f(CW$SHELL\fR to see whether the shell was a \fB*csh\fR shell. If so the
variables would be set using \fBsetenv\fR. Otherwise they would be set
using \fB=\fR. The caused the content of the variable to be repeated:
.PP
echo \f(CW$SHELL\fR | grep \*(L"/t\e{0,1\e}csh\*(R" > /dev/null && setenv \s-1VAR\s0 foo ||
export VAR=foo
